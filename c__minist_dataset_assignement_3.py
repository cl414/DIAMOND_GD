# -*- coding: utf-8 -*-
"""C_ MINIST_DATASET_ASSIGNEMENT_3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17LOQt1plPfkZakJ81SlGoHPueT0R0Cu2

![UR Logo](https://www.ur.ac.rw/fileadmin/templates/images/logo-ur.png)

# **UNIVERSITY OF RWANDA**  
### *African Centre of Excellence in Data Science (ACD-DS)*  

---

## **MNIST DATASET WORKFLOW**  

### **AUTHOR:**  
**JEAN CLAUDE HARERIMANA**  
Aspirant in Data Science *(Data Mining Specialization)*  
African Centre of Excellence in Data Science (ACD-DS)  
University of Rwanda - ECBSS  

### **Academic Year:**  
2024 - 2025  

---

##  **MAIN STAGES USING THE MNIST DATASET**

1. **Import Required Libraries**  
2. **Load the MNIST Dataset**  
3. **Preprocess the Data**  
4. **Build the Neural Network Model**  
5. **Compile the Model**  
6. **Train the Model (SGD & Mini-Batch)**  
7. **Evaluate the Model**  
8. **Calculate Misclassification Rate**  
9. **Generate Confusion Matrix**  
10. **Make Predictions**  
11. **Visualize Results**  
12. **Save and Reload the Model**  

---

**Submitted:** `19 July 2025`  
*Developed using Python in Google Colab*

## WHAT IS MNIST DATASET

The **MNIST dataset** is a popular benchmark dataset in machine learning, used for **handwritten digit recognition**. It consists of grayscale images of digits from **0 to 9**.

### KEY FEATURES:
- **Images:** 28x28 pixels (grayscale)
- **Classes:** 10 (digits 0 to 9)
- **Training set:** 60,000 images
- **Test set:** 10,000 images
- **Pixel values:** Range from 0 (black) to 255 (white)

##PURPOSE:
MNIST is widely used to:
- Train and evaluate **image classification models**
- Understand and test **neural network architectures**
- Learn basic **computer vision** and **deep learning** concepts

It is an ideal dataset for beginners to learn and practice digit classification tasks.

# STAGE 1.LOAD THE MNIST DATASET
"""

from tensorflow.keras.datasets import mnist

# Load training and test data
(x_train, y_train), (x_test, y_test) = mnist.load_data()

print("Training set shape:", x_train.shape)
print("Test set shape:", x_test.shape)

"""# STAGE 2.PREPROCESS DATASET"""

# Normalize pixel values to [0, 1]
x_train = x_train / 255.0
x_test = x_test / 255.0

# Reshape for CNN (add channel dimension)
x_train = x_train.reshape(-1, 28, 28, 1)
x_test = x_test.reshape(-1, 28, 28, 1)

print("Training data reshaped to:", x_train.shape)

"""#  STAGE 3.BUILD THE CNN MODEL"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout

model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    MaxPooling2D(pool_size=(2, 2)),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D(pool_size=(2, 2)),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.3),
    Dense(10, activation='softmax')
])

"""#  STAGE 4.COMPLILE THE MODEL"""

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

"""#STAGE 5.TRAIN THE MODEL"""

history = model.fit(x_train, y_train, epochs=5, batch_size=64, validation_split=0.1)

"""#STAGE 6.EVALUATE THE MODEL"""

loss, accuracy = model.evaluate(x_test, y_test)
print(f" Final Test Accuracy: {accuracy * 100:.2f}%")

"""#STAGE 7.PREDICT AND VIZUALIZE RESULT FROM MODEL"""

import matplotlib.pyplot as plt
import numpy as np

# Predict on test data
predictions = model.predict(x_test)

# Visualize first 6 test images with predictions
for i in range(6):
    plt.subplot(2, 3, i + 1)
    plt.imshow(x_test[i].reshape(28, 28), cmap='gray')
    plt.title(f"True: {y_test[i]}, Pred: {np.argmax(predictions[i])}")
    plt.axis('off')
plt.tight_layout()
plt.show()

"""#STAGE 8.EXPLORE THE MODEL'S PERFOMENCE"""

from sklearn.metrics import confusion_matrix
import seaborn as sns

# Get predicted classes
y_pred_classes = np.argmax(predictions, axis=1)

# Calculate confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred_classes)

# Visualize confusion matrix
plt.figure(figsize=(10, 8))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.show()

"""#STAGE 9.MISSCLASIFICATION IMAGES"""

# Find misclassified images
misclassified_indices = np.where(y_test != y_pred_classes)[0]

# Visualize some misclassified images (e.g., the first 10)
num_to_show = 10
if len(misclassified_indices) > 0:
    plt.figure(figsize=(10, 5))
    for i, index in enumerate(misclassified_indices[:num_to_show]):
        plt.subplot(2, 5, i + 1)
        plt.imshow(x_test[index].reshape(28, 28), cmap='gray')
        plt.title(f"True: {y_test[index]}, Pred: {y_pred_classes[index]}")
        plt.axis('off')
    plt.tight_layout()
    plt.show()
else:
    print("No misclassified images found.")

"""#STAGE 10.CLASSIFICATION REPORT OF MODEL"""

from sklearn.metrics import classification_report

# Get classification report
class_report = classification_report(y_test, y_pred_classes)

# Print the classification report
print("\nClassification Report:")
print(class_report)

"""#STAGE 11.SAVE THE TRAINED MODEL"""

# Save the trained model
model.save('mnist_cnn_model.keras')
print("Model saved successfully!")

"""**END**!!"""